#!/usr/bin/env bash
# Stop all vLLM servers (ports 8001, 8002)
# Usage: ./scripts/vllm/stop.sh

set -e

echo "ðŸ›‘ Stopping vLLM servers..."

# Stop 3B server (port 8001)
if pgrep -f "vllm.entrypoints.openai.api_server.*8001" > /dev/null; then
    echo "   Stopping 3B server (port 8001)..."
    pkill -f "vllm.entrypoints.openai.api_server.*8001"
    echo "   âœ… 3B server stopped"
else
    echo "   â„¹ï¸  No 3B server running on port 8001"
fi

# Stop 7B server (port 8002)
if pgrep -f "vllm.entrypoints.openai.api_server.*8002" > /dev/null; then
    echo "   Stopping 7B server (port 8002)..."
    pkill -f "vllm.entrypoints.openai.api_server.*8002"
    echo "   âœ… 7B server stopped"
else
    echo "   â„¹ï¸  No 7B server running on port 8002"
fi

sleep 2
echo "âœ… All vLLM servers stopped"
echo ""

# Best-effort GPU memory report (optional).
if command -v nvidia-smi >/dev/null 2>&1; then
    nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits | \
        awk '{printf "   GPU Memory: %d / %d MiB (%.1f%% free)\n", $1, $2, 100*(1-$1/$2)}' || true
else
    echo "   (nvidia-smi not found; skipping GPU memory report)"
fi
